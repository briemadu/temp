@inproceedings{madureira-schlangen-2020-incremental,
    title = "Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental {NLU}",
    author = "Madureira, Brielen  and
      Schlangen, David",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.26",
    doi = "10.18653/v1/2020.emnlp-main.26",
    pages = "357--374",
    abstract = "While humans process language incrementally, the best language encoders currently used in NLP do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiLSTMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five models on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The {``}omni-directional{''} BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncated training), or the testing procedure, by delaying the output until some right context is available or by incorporating hypothetical right contexts generated by a language model like GPT-2.",
}

@inproceedings{kahardipraja-etal-2021-towards,
    title = "Towards Incremental Transformers: An Empirical Analysis of Transformer Models for Incremental {NLU}",
    author = "Kahardipraja, Patrick  and
      Madureira, Brielen  and
      Schlangen, David",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.90",
    doi = "10.18653/v1/2021.emnlp-main.90",
    pages = "1178--1189",
    abstract = "Incremental processing allows interactive systems to respond based on partial inputs, which is a desirable property e.g. in dialogue agents. The currently popular Transformer architecture inherently processes sequences as a whole, abstracting away the notion of time. Recent work attempts to apply Transformers incrementally via restart-incrementality by repeatedly feeding, to an unchanged model, increasingly longer input prefixes to produce partial outputs. However, this approach is computationally costly and does not scale efficiently for long sequences. In parallel, we witness efforts to make Transformers more efficient, e.g. the Linear Transformer (LT) with a recurrence mechanism. In this work, we examine the feasibility of LT for incremental NLU in English. Our results show that the recurrent LT model has better incremental performance and faster inference speed compared to the standard Transformer and LT with restart-incrementality, at the cost of part of the non-incremental (full sequence) quality. We show that the performance drop can be mitigated by training the model to wait for right context before committing to an output and that training with input prefixes is beneficial for delivering correct partial outputs.",
}

@inproceedings{madureira-2021-flamingos,
    title = "Flamingos and Hedgehogs in the Croquet-Ground: Teaching Evaluation of {NLP} Systems for Undergraduate Students",
    author = "Madureira, Brielen",
    editor = "Jurgens, David  and
      Kolhatkar, Varada  and
      Li, Lucy  and
      Mieskes, Margot  and
      Pedersen, Ted",
    booktitle = "Proceedings of the Fifth Workshop on Teaching NLP",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.teachingnlp-1.14",
    doi = "10.18653/v1/2021.teachingnlp-1.14",
    pages = "87--91",
    abstract = "This report describes the course Evaluation of NLP Systems, taught for Computational Linguistics undergraduate students during the winter semester 20/21 at the University of Potsdam, Germany. It was a discussion-based seminar that covered different aspects of evaluation in NLP, namely paradigms, common procedures, data annotation, metrics and measurements, statistical significance testing, best practices and common approaches in specific NLP tasks and applications.",
}


@inproceedings{madureira-schlangen-2022-visual,
    title = "Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge",
    author = "Madureira, Brielen  and
      Schlangen, David",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-short.73",
    doi = "10.18653/v1/2022.acl-short.73",
    pages = "651--664",
    abstract = "Cognitively plausible visual dialogue models should keep a mental scoreboard of shared established facts in the dialogue context. We propose a theory-based evaluation method for investigating to what degree models pretrained on the VisDial dataset incrementally build representations that appropriately do scorekeeping. Our conclusion is that the ability to make the distinction between shared and privately known statements along the dialogue is moderately present in the analysed models, but not always incrementally consistent, which may partially be due to the limited need for grounding interactions in the original task.",
}

@inproceedings{madureira-etal-2023-road,
    title = "The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling",
    author = "Madureira, Brielen  and
      Kahardipraja, Patrick  and
      Schlangen, David",
    editor = "Stoyanchev, Svetlana  and
      Joty, Shafiq  and
      Schlangen, David  and
      Dusek, Ondrej  and
      Kennington, Casey  and
      Alikhani, Malihe",
    booktitle = "Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2023",
    address = "Prague, Czechia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.sigdial-1.14",
    doi = "10.18653/v1/2023.sigdial-1.14",
    pages = "156--167",
    abstract = "Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.",
}

@inproceedings{madureira-etal-2023-revising,
    title = "Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing",
    author = "Madureira, Brielen  and
      {\c{C}}elikkol, Pelin  and
      Schlangen, David",
    editor = "Jiang, Jing  and
      Reitter, David  and
      Deng, Shumin",
    booktitle = "Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.conll-1.22",
    doi = "10.18653/v1/2023.conll-1.22",
    pages = "335--351",
    abstract = "In NLP, incremental processors produce output in instalments, based on incoming prefixes of the linguistic input. Some tokens trigger revisions, causing edits to the output hypothesis, but little is known about why models revise when they revise. A policy that detects the time steps where revisions should happen can improve efficiency. Still, retrieving a suitable signal to train a revision policy is an open problem, since it is not naturally available in datasets. In this work, we investigate the appropriateness of regressions and skips in human reading eye-tracking data as signals to inform revision policies in incremental sequence labelling. Using generalised mixed-effects models, we find that the probability of regressions and skips by humans can potentially serve as useful predictors for revisions in BiLSTMs and Transformer models, with consistent results for various languages.",
}

@inproceedings{madureira-schlangen-2023-instruction,
    title = "Instruction Clarification Requests in Multimodal Collaborative Dialogue Games: Tasks, and an Analysis of the {C}o{D}raw Dataset",
    author = "Madureira, Brielen  and
      Schlangen, David",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.169",
    doi = "10.18653/v1/2023.eacl-main.169",
    pages = "2303--2319",
    abstract = "In visual instruction-following dialogue games, players can engage in repair mechanisms in face of an ambiguous or underspecified instruction that cannot be fully mapped to actions in the world. In this work, we annotate Instruction Clarification Requests (iCRs) in CoDraw, an existing dataset of interactions in a multimodal collaborative dialogue game. We show that it contains lexically and semantically diverse iCRs being produced self-motivatedly by players deciding to clarify in order to solve the task successfully. With 8.8k iCRs found in 9.9k dialogues, CoDraw-iCR (v1) is a large spontaneous iCR corpus, making it a valuable resource for data-driven research on clarification in dialogue. We then formalise and provide baseline models for two tasks: Determining when to make an iCR and how to recognise them, in order to investigate to what extent these tasks are learnable from data.",
}

@inproceedings{chalamalasetti-etal-2023-clembench,
    title = "clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents",
    author = {Chalamalasetti, Kranti  and
      G{\"o}tze, Jana  and
      Hakimov, Sherzod  and
      Madureira, Brielen  and
      Sadler, Philipp  and
      Schlangen, David},
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.689",
    doi = "10.18653/v1/2023.emnlp-main.689",
    pages = "11174--11219",
    abstract = "Recent work has proposed a methodology for the systematic evaluation of {``}Situated Language Understanding Agents{''} {---} agents that operate in rich linguistic and non-linguistic contexts {---} through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable of following game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models generally performing better. The metrics even for the comparatively simple example games are far from being saturated, suggesting that the proposed instrument will remain to have diagnostic value.",
}


@inproceedings{kahardipraja-etal-2023-tapir,
    title = "{TAPIR}: Learning Adaptive Revision for Incremental Natural Language Understanding with a Two-Pass Model",
    author = "Kahardipraja, Patrick  and
      Madureira, Brielen  and
      Schlangen, David",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.257",
    doi = "10.18653/v1/2023.findings-acl.257",
    pages = "4173--4197",
    abstract = "Language is by its very nature incremental in how it is produced and processed. This property can be exploited by NLP systems to produce fast responses, which has been shown to be beneficial for real-time interactive applications. Recent neural network-based approaches for incremental processing mainly use RNNs or Transformers. RNNs are fast but monotonic (cannot correct earlier output, which can be necessary in incremental processing). Transformers, on the other hand, consume whole sequences, and hence are by nature non-incremental. A restart-incremental interface that repeatedly passes longer input prefixes can be used to obtain partial outputs, while providing the ability to revise. However, this method becomes costly as the sentence grows longer. In this work, we propose the Two-pass model for AdaPtIve Revision (TAPIR) and introduce a method to obtain an incremental supervision signal for learning an adaptive revision policy. Experimental results on sequence labelling show that our model has better incremental performance and faster inference speed compared to restart-incremental Transformers, while showing little degradation on full sequences.",
}

@inproceedings{madureira-2023-incrementally,
    title = "Incrementally Enriching the Common Ground: A Research Path",
    author = "Madureira, Brielen",
    editor = "Hudecek, Vojtech  and
      Schmidtova, Patricia  and
      Dinkar, Tanvi  and
      Chiyah-Garcia, Javier  and
      Sieinska, Weronika",
    booktitle = "Proceedings of the 19th Annual Meeting of the Young Reseachers' Roundtable on Spoken Dialogue Systems",
    month = sep,
    year = "2023",
    address = "Prague, Czechia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.yrrsds-1.21",
    pages = "57--58",
    abstract = "I am broadly interested in evaluation of dialogue systems, in all its many facets: The data they are trained on, their ability to perform a task successfully, their skills with respect to various dialogue phenomena, their resemblance to human cognitive processes, and their ethical and societal impact. More specifically, my research topics focus on understanding the possibilities and limits of current multimodal neural network-based models to incrementally encode information for natural language understanding in general and also for building common ground and asking for clarification. Besides, I am interested in dialogue games as a means to elicit and collect dialogue data and to evaluate the abilities of dialogue models.",
}

@inproceedings{madureira-schlangen-2024-taking,
    title = "Taking Action Towards Graceful Interaction: The Effects of Performing Actions on Modelling Policies for Instruction Clarification Requests",
    author = "Madureira, Brielen  and
      Schlangen, David",
    editor = "Pyatkin, Valentina  and
      Fried, Daniel  and
      Stengel-Eskin, Elias  and
      Stengel-Eskin, Elias  and
      Liu, Alisa  and
      Pezzelle, Sandro",
    booktitle = "Proceedings of the Third Workshop on Understanding Implicit and Underspecified Language",
    month = mar,
    year = "2024",
    address = "Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.unimplicit-1.1",
    pages = "1--21",
    abstract = "Clarification requests are a mechanism to help solve communication problems, e.g. due to ambiguity or underspecification, in instruction-following interactions. Despite their importance, even skilful models struggle with producing or interpreting such repair acts. In this work, we test three hypotheses concerning the effects of action taking as an auxiliary task in modelling iCR policies. Contrary to initial expectations, we conclude that its contribution to learning an iCR policy is limited, but some information can still be extracted from prediction uncertainty. We present further evidence that even well-motivated, Transformer-based models fail to learn good policies for when to ask Instruction CRs (iCRs), while the task of determining what to ask about can be more successfully modelled. Considering the implications of these findings, we further discuss the shortcomings of the data-driven paradigm for learning meta-communication acts.",
}

@InCollection{BPLN_livro_cap-dialogo-interatividade:2024,
    author    = {Madureira, Brielen},
    title     = {Diálogo e Interatividade},
    booktitle = {Processamento de Linguagem Natural: Conceitos, Técnicas e Aplicações em Português},
    publisher = {BPLN},
    year      = {2024},
    editor    = {Caseli, H. M. and Nunes, M. G. V.},
    type      = {Book Chapter},
    chapter   = {17},
    edition   = {2},
    isbn      = {978-65-00-95750-1},
    url       = {https://brasileiraspln.com/livro-pln/2a-edicao/parte-interacao/cap-dialogo-interatividade/cap-dialogo-interatividade.html},
}

@InCollection{BPLN_livro_cap-avaliacao:2024,
    author    = {Madureira, Brielen},
    title     = {Avaliação de tecnologias de linguagem},
    booktitle = {Processamento de Linguagem Natural: Conceitos, Técnicas e Aplicações em Português},
    publisher = {BPLN},
    year      = {2024},
    editor    = {Caseli, H. M. and Nunes, M. G. V.},
    type      = {Book Chapter},
    chapter   = {14},
    edition   = {2},
    isbn      = {978-65-00-95750-1},
    url       = {https://brasileiraspln.com/livro-pln/2a-edicao/parte-dados-avaliacao/cap-avaliacao/cap-avaliacao.html},
}

@inproceedings{madureira2020overview,
      title={An Overview of Natural Language State Representation for Reinforcement Learning}, 
      author={Brielen Madureira and David Schlangen},
      year={2020},
      month={july},
      booktitle ={ICML Workshop on Language in Reinforcement Learning (LaReL)},
      url={https://doi.org/10.48550/arXiv.2007.09774}
}

@inproceedings{madureira-schlangen-2023-telling,
    title = "``Are you telling me to put glasses on the dog?'' Content-Grounded Annotation of Instruction Clarification Requests in the CoDraw Dataset",
    author = "Madureira, Brielen  and
      Schlangen, David",
    booktitle = "Proceedings of the 27th Workshop on the Semantics and Pragmatics of Dialogue - Poster Abstracts",
    month = aug,
    year = "2023",
    address = "Maribor, Slovenia",
    publisher = "SEMDIAL",
    url = "http://semdial.org/anthology/Z23-Madureira_semdial_0025.pdf",
}

@inproceedings{madureira-etal-2024-time,
    title = "When Only Time Will Tell: Interpreting How Transformers Process Local Ambiguities Through the Lens of Restart-Incrementality",
    author = "Madureira, Brielen  and
      Kahardipraja, Patrick  and
      Schlangen, David",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.260",
    doi = "10.18653/v1/2024.acl-long.260",
    pages = "4722--4749",
    abstract = "Incremental models that process sentences one token at a time will sometimes encounter points where more than one interpretation is possible. Causal models are forced to output one interpretation and continue, whereas models that can revise may edit their previous output as the ambiguity is resolved. In this work, we look at how restart-incremental Transformers build and update internal states, in an effort to shed light on what processes cause revisions not viable in autoregressive models. We propose an interpretable way to analyse the incremental states, showing that their sequential structure encodes information on the garden path effect and its resolution. Our method brings insights on various bidirectional encoders for contextualised meaning representation and dependency parsing, contributing to show their advantage over causal models when it comes to revisions.",
}


@incollection{madureira-lasota,
    author = {Madureira, Brielen and Lasota, Lucas},
    title = {Das Inquietudes em Tecnologias de Linguagem},
    booktitle = {Novas Tecnologias},
    publisher = {Editora Casa do Direito},
    year = {2023},
    editor={Mariana de Angelo Alegre}
}

@inproceedings{madureira-schlangen-2024-couldnt,
    title = "It Couldn{'}t Help but Overhear: On the Limits of Modelling Meta-Communicative Grounding Acts with Supervised Learning",
    author = "Madureira, Brielen  and
      Schlangen, David",
    editor = "Kawahara, Tatsuya  and
      Demberg, Vera  and
      Ultes, Stefan  and
      Inoue, Koji  and
      Mehri, Shikib  and
      Howcroft, David  and
      Komatani, Kazunori",
    booktitle = "Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2024",
    address = "Kyoto, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.sigdial-1.13",
    doi = "10.18653/v1/2024.sigdial-1.13",
    pages = "149--158",
    abstract = "Active participation in a conversation is key to building common ground, since understanding is jointly tailored by producers and recipients. Overhearers are deprived of the privilege of performing grounding acts and can only conjecture about intended meanings. Still, data generation and annotation, modelling, training and evaluation of NLP dialogue models place reliance on the overhearing paradigm. How much of the underlying grounding processes are thereby forfeited? As we show, there is evidence pointing to the impossibility of properly modelling human meta-communicative acts with data-driven learning models. In this paper, we discuss this issue and provide a preliminary analysis on the variability of human decisions for requesting clarification. Most importantly, we wish to bring this topic back to the community{'}s table, encouraging discussion on the consequences of having models designed to only {``}listen in{'}{''}.",
}

